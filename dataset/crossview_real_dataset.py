# dataset/crossview_real_dataset.py
"""
ä½¿ç”¨çœŸå®æ ‡ç­¾çš„è·¨è§†è§’åœ°ç†å®šä½æ•°æ®é›†
"""
import os
import torch
from torch.utils.data import Dataset
from PIL import Image
import numpy as np
import json

class RealUniversityDataset(Dataset):
    """ä½¿ç”¨çœŸå®æ ‡ç­¾çš„Universityæ•°æ®é›†"""
    
    def __init__(self, root_dir='University-Release', split='train',
                 uav_size=(256, 256), sat_size=(512, 512), max_samples=None):
        super().__init__()
        
        self.root_dir = root_dir
        self.split = split
        self.uav_size = uav_size
        self.sat_size = sat_size
        self.max_samples = max_samples
        
        print(f"\nğŸ“‚ åˆå§‹åŒ– {split} æ•°æ®é›† (çœŸå®æ ‡ç­¾)...")
        
        # åŠ è½½æ ‡ç­¾æ–‡ä»¶
        label_file = f'{split}_annotations.json'
        if os.path.exists(label_file):
            with open(label_file, 'r', encoding='utf-8') as f:
                self.data = json.load(f)
            print(f"ğŸ“„ åŠ è½½æ ‡ç­¾æ–‡ä»¶: {label_file}")
        else:
            print(f"âŒ æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {label_file}")
            self.data = []
        
        # å¤„ç†ä¸åŒæ ¼å¼
        if split == 'train':
            # è®­ç»ƒé›†ï¼šç›´æ¥ä½¿ç”¨åˆ—è¡¨
            self.annotations = self.data
            self.is_test = False
        else:
            # æµ‹è¯•é›†ï¼šéœ€è¦ç‰¹æ®Šå¤„ç†
            self.queries = self.data.get('queries', [])
            self.gallery = self.data.get('gallery', [])
            self.is_test = True
            
            # ä¸ºæµ‹è¯•åˆ›å»ºæ ·æœ¬åˆ—è¡¨ï¼ˆæ¯ä¸ªæŸ¥è¯¢åŒ¹é…å¯¹åº”çš„galleryï¼‰
            self.samples = self._create_test_samples()
            self.annotations = self.samples
        
        print(f"âœ… åŠ è½½ {len(self.annotations)} ä¸ªæ ·æœ¬")
        
        # é™åˆ¶æ ·æœ¬æ•°é‡
        if max_samples and len(self.annotations) > max_samples:
            self.annotations = self.annotations[:max_samples]
            print(f"ğŸ“Š é™åˆ¶ä¸º {max_samples} ä¸ªæ ·æœ¬")
    
    def _create_test_samples(self):
        """ä¸ºæµ‹è¯•é›†åˆ›å»ºæ ·æœ¬ï¼ˆæŸ¥è¯¢-å‚è€ƒé…å¯¹ï¼‰ - ä¿®å¤ç‰ˆ"""
        samples = []
        
        print(f"æŸ¥è¯¢æ•°é‡: {len(self.queries)}")
        print(f"å‚è€ƒåº“æ•°é‡: {len(self.gallery)}")
        
        # æ–¹æ³•1: ç®€å•é…å¯¹ï¼ˆæ¯ä¸ªæŸ¥è¯¢é…ç¬¬ä¸€ä¸ªå‚è€ƒï¼‰
        # è¿™ç”¨äºæµ‹è¯•ï¼Œå®é™…åº”è¯¥æ˜¯æ£€ç´¢ä»»åŠ¡
        for i, query in enumerate(self.queries[:min(100, len(self.queries))]):
            query_path = query.get('path', '')
            query_id = query.get('query_id', '')
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå‚è€ƒå›¾åƒ
            if self.gallery:
                gallery = self.gallery[i % len(self.gallery)]  # å¾ªç¯ä½¿ç”¨
                samples.append({
                    'uav_path': query_path,
                    'sat_path': gallery.get('path', ''),
                    'lat': gallery.get('lat', 0.0),
                    'lon': gallery.get('lon', 0.0),
                    'query_id': query_id,
                    'gallery_id': gallery.get('gallery_id', '')
                })
        
        print(f"ğŸ”— åˆ›å»º {len(samples)} ä¸ªæµ‹è¯•æ ·æœ¬é…å¯¹")
        return samples
    def __len__(self):
        return len(self.annotations)
    
    def __getitem__(self, idx):
        annotation = self.annotations[idx]
        
        try:
            # è·å–è·¯å¾„å’Œåæ ‡
            if isinstance(annotation, dict):
                # è®­ç»ƒé›†æ ¼å¼
                if 'uav_path' in annotation:
                    uav_path = annotation['uav_path']
                    sat_path = annotation['sat_path']
                # æµ‹è¯•é›†æ ¼å¼ï¼ˆæˆ‘ä»¬å·²ç»è½¬æ¢äº†ï¼‰
                else:
                    uav_path = annotation.get('uav_path', '')
                    sat_path = annotation.get('sat_path', '')
                
                lat = annotation.get('lat', 0.0)
                lon = annotation.get('lon', 0.0)
            else:
                # å¤‡ç”¨æ–¹æ¡ˆ
                lat, lon = 0.0, 0.0
                uav_path = sat_path = ''
            
            # æ„å»ºå®Œæ•´è·¯å¾„
            full_uav_path = os.path.join(self.root_dir, uav_path)
            full_sat_path = os.path.join(self.root_dir, sat_path)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(full_uav_path):
                # å°è¯•ä¸åŒçš„è·¯å¾„æ ¼å¼
                alt_path = uav_path.replace('street/', 'drone/').replace('/1.jpg', '/image-01.jpeg')
                full_uav_path = os.path.join(self.root_dir, alt_path)
            
            if not os.path.exists(full_sat_path):
                # å°è¯•ä¸åŒçš„å«æ˜Ÿå›¾åƒè·¯å¾„
                alt_path = sat_path.replace('satellite/', 'satellite/')
                full_sat_path = os.path.join(self.root_dir, alt_path)
            
            # åŠ è½½å›¾åƒ
            uav_img = Image.open(full_uav_path).convert('RGB')
            sat_img = Image.open(full_sat_path).convert('RGB')
            
            # è°ƒæ•´å¤§å°
            uav_img = uav_img.resize(self.uav_size, Image.BILINEAR)
            sat_img = sat_img.resize(self.sat_size, Image.BILINEAR)
            
            lat_min, lat_max = 40.000, 40.098
            lon_min, lon_max = -75.000, -74.902
            
            norm_lat = (lat - lat_min) / (lat_max - lat_min)
            norm_lon = (lon - lon_min) / (lon_max - lon_min)
            
            # ç¡®ä¿åœ¨ [0, 1] èŒƒå›´
            norm_lat = max(0.0, min(1.0, norm_lat))
            norm_lon = max(0.0, min(1.0, norm_lon))
            
            # è½¬æ¢ä¸ºå¼ é‡
            uav_array = np.array(uav_img, dtype=np.float32) / 255.0
            sat_array = np.array(sat_img, dtype=np.float32) / 255.0
            
            uav_tensor = torch.from_numpy(uav_array).permute(2, 0, 1)
            sat_tensor = torch.from_numpy(sat_array).permute(2, 0, 1)
            
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å›¾åƒå‡ºé”™ (idx={idx}): {e}")
            print(f"  UAVè·¯å¾„: {full_uav_path if 'full_uav_path' in locals() else 'N/A'}")
            print(f"  å«æ˜Ÿè·¯å¾„: {full_sat_path if 'full_sat_path' in locals() else 'N/A'}")
            
            # è¿”å›éšæœºå¼ é‡
            uav_tensor = torch.randn(3, *self.uav_size)
            sat_tensor = torch.randn(3, *self.sat_size)
            lat, lon = 0.0, 0.0
        
        return {
        'uav': uav_tensor,
        'satellite': sat_tensor,
        'lat': torch.tensor(norm_lat, dtype=torch.float32),
        'lon': torch.tensor(norm_lon, dtype=torch.float32),
        'raw_lat': torch.tensor(lat, dtype=torch.float32),  # ä¿ç•™åŸå§‹åæ ‡
        'raw_lon': torch.tensor(lon, dtype=torch.float32),
        'idx': idx
    }


# æµ‹è¯•å‡½æ•°
def test_dataset():
    """æµ‹è¯•æ•°æ®é›†"""
    print("ğŸ§ª æµ‹è¯•çœŸå®æ ‡ç­¾æ•°æ®é›†...")
    
    # æµ‹è¯•è®­ç»ƒé›†
    print("\n1. æµ‹è¯•è®­ç»ƒé›†:")
    train_dataset = RealUniversityDataset(
        root_dir='University-Release',
        split='train',
        max_samples=5
    )
    
    if len(train_dataset) > 0:
        sample = train_dataset[0]
        print(f"  æ ·æœ¬æ•°: {len(train_dataset)}")
        print(f"  UAVå½¢çŠ¶: {sample['uav'].shape}")
        print(f"  å«æ˜Ÿå½¢çŠ¶: {sample['satellite'].shape}")
        print(f"  çœŸå®åæ ‡: ({sample['lat'].item():.6f}, {sample['lon'].item():.6f})")
        print(f"  æ•°æ®ç±»å‹: {sample['uav'].dtype}")
    
    # æµ‹è¯•æµ‹è¯•é›†
    print("\n2. æµ‹è¯•æµ‹è¯•é›†:")
    test_dataset = RealUniversityDataset(
        root_dir='University-Release',
        split='test',
        max_samples=5
    )
    
    if len(test_dataset) > 0:
        sample = test_dataset[0]
        print(f"  æ ·æœ¬æ•°: {len(test_dataset)}")
        print(f"  çœŸå®åæ ‡: ({sample['lat'].item():.6f}, {sample['lon'].item():.6f})")

if __name__ == '__main__':
    test_dataset()