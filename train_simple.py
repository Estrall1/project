# train_improved.py
import os
import torch
import torch.nn as nn
import torch.optim as optim
import json
import numpy as np
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

print("ğŸš€ æ”¹è¿›ç‰ˆè®­ç»ƒå¼€å§‹...")

# 1. åŠ è½½æ›´å¤šæ•°æ®
with open('train_annotations.json', 'r') as f:
    all_data = json.load(f)
    
print(f"æ€»æ•°æ®é‡: {len(all_data)} ä¸ªæ ·æœ¬")

# ä½¿ç”¨æ›´å¤šæ•°æ®ï¼ˆä¾‹å¦‚800ä¸ªï¼‰
train_data = all_data[:800]
print(f"ä½¿ç”¨ {len(train_data)} ä¸ªæ ·æœ¬è¿›è¡Œè®­ç»ƒ")

# å½’ä¸€åŒ–å‚æ•°
lats = [item['lat'] for item in train_data]
lons = [item['lon'] for item in train_data]
lat_min, lat_max = min(lats), max(lats)
lon_min, lon_max = min(lons), max(lons)

def normalize_coord(coord, min_val, max_val):
    return (coord - min_val) / (max_val - min_val)

# å‡†å¤‡æ•°æ®
norm_labels = []
for item in train_data:
    norm_lat = normalize_coord(item['lat'], lat_min, lat_max)
    norm_lon = normalize_coord(item['lon'], lon_min, lon_max)
    norm_labels.append([norm_lat, norm_lon])

norm_labels = torch.tensor(norm_labels, dtype=torch.float32)

# 2. åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
indices = list(range(len(train_data)))
train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)

# 3. æ”¹è¿›çš„æ¨¡å‹
class ImprovedModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3, 16, 3, stride=2, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.Conv2d(16, 32, 3, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d(1)
        )
        self.fc = nn.Sequential(
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 8),
            nn.ReLU(),
            nn.Linear(8, 2),
            nn.Sigmoid()
        )
    
    def forward(self, uav_img, sat_img):
        uav_feat = self.conv(uav_img).view(uav_img.size(0), -1)
        sat_feat = self.conv(sat_img).view(sat_img.size(0), -1)
        combined = torch.cat([uav_feat, sat_feat], dim=1)
        return {'fine_coords': self.fc(combined)}

# 4. è®­ç»ƒå‡†å¤‡
model = ImprovedModel()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)

# ç”Ÿæˆè™šæ‹Ÿå›¾åƒæ•°æ®
uav_imgs = torch.randn(len(train_data), 3, 256, 256)
sat_imgs = torch.randn(len(train_data), 3, 512, 512)

# åˆ†ç¦»è®­ç»ƒ/éªŒè¯æ•°æ®
train_uav = uav_imgs[train_idx]
train_sat = sat_imgs[train_idx]
train_labels = norm_labels[train_idx]

val_uav = uav_imgs[val_idx]
val_sat = sat_imgs[val_idx]
val_labels = norm_labels[val_idx]

print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
print(f"è®­ç»ƒé›†: {len(train_idx)} ä¸ªæ ·æœ¬")
print(f"éªŒè¯é›†: {len(val_idx)} ä¸ªæ ·æœ¬")
print(f"åæ ‡èŒƒå›´: çº¬åº¦ [{lat_min:.3f}, {lat_max:.3f}]")
print(f"          ç»åº¦ [{lon_min:.3f}, {lon_max:.3f}]")

# 5. è®­ç»ƒå¾ªç¯
epochs = 50
batch_size = 16
train_losses = []
val_losses = []

print(f"\nâ³ å¼€å§‹è®­ç»ƒ {epochs} è½®...")

for epoch in range(epochs):
    model.train()
    epoch_loss = 0
    
    # éšæœºæ‰“ä¹±è®­ç»ƒæ•°æ®
    indices = torch.randperm(len(train_idx))
    
    for i in range(0, len(train_idx), batch_size):
        batch_indices = indices[i:i+batch_size]
        
        batch_uav = train_uav[batch_indices]
        batch_sat = train_sat[batch_indices]
        batch_labels = train_labels[batch_indices]
        
        outputs = model(batch_uav, batch_sat)
        loss = criterion(outputs['fine_coords'], batch_labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        epoch_loss += loss.item()
    
    avg_train_loss = epoch_loss / (len(train_idx) // batch_size)
    train_losses.append(avg_train_loss)
    
    # éªŒè¯
    model.eval()
    with torch.no_grad():
        val_outputs = model(val_uav, val_sat)
        val_loss = criterion(val_outputs['fine_coords'], val_labels)
        val_losses.append(val_loss.item())
    
    # æ›´æ–°å­¦ä¹ ç‡
    scheduler.step()
    
    # æ¯5è½®æ‰“å°ä¸€æ¬¡
    if (epoch + 1) % 5 == 0 or epoch == 0:
        current_lr = optimizer.param_groups[0]['lr']
        print(f"Epoch {epoch+1}/{epochs}: è®­ç»ƒæŸå¤±={avg_train_loss:.6f}, "
              f"éªŒè¯æŸå¤±={val_loss.item():.6f}, LR={current_lr:.6f}")
        
        # æ˜¾ç¤ºé¢„æµ‹ç¤ºä¾‹
        with torch.no_grad():
            test_outputs = model(uav_imgs[:3], sat_imgs[:3])
            for j in range(3):
                pred = test_outputs['fine_coords'][j].numpy()
                true = norm_labels[j].numpy()
                print(f"  æ ·æœ¬{j+1}: é¢„æµ‹({pred[0]:.3f},{pred[1]:.3f}) çœŸå®({true[0]:.3f},{true[1]:.3f})")

# 6. ä¿å­˜æ¨¡å‹
os.makedirs('improved_model', exist_ok=True)
torch.save({
    'model_state_dict': model.state_dict(),
    'lat_min': lat_min, 'lat_max': lat_max,
    'lon_min': lon_min, 'lon_max': lon_max,
    'train_size': len(train_data),
    'train_losses': train_losses,
    'val_losses': val_losses,
    'final_train_loss': train_losses[-1],
    'final_val_loss': val_losses[-1]
}, 'improved_model/improved_trained.pth')

print(f"\nâœ… è®­ç»ƒå®Œæˆ! æ¨¡å‹ä¿å­˜åˆ°: improved_model/improved_trained.pth")

# 7. ç»˜åˆ¶æŸå¤±æ›²çº¿
plt.figure(figsize=(10, 6))
plt.plot(train_losses, 'b-', label='Training Loss', linewidth=2)
plt.plot(val_losses, 'r--', label='Validation Loss', linewidth=2)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Curves')
plt.legend()
plt.grid(True, alpha=0.3)
plt.savefig('improved_model/loss_curves.png', dpi=150, bbox_inches='tight')
print("âœ… ä¿å­˜æŸå¤±æ›²çº¿å›¾: improved_model/loss_curves.png")

# 8. æœ€ç»ˆè¯„ä¼°
model.eval()
with torch.no_grad():
    # è®­ç»ƒé›†è¯„ä¼°
    train_outputs = model(train_uav[:50], train_sat[:50])
    train_pred = train_outputs['fine_coords'].numpy()
    train_true = train_labels[:50].numpy()
    
    # éªŒè¯é›†è¯„ä¼°
    val_outputs = model(val_uav[:50], val_sat[:50])
    val_pred = val_outputs['fine_coords'].numpy()
    val_true = val_labels[:50].numpy()
    
    # è®¡ç®—å¹³å‡è¯¯å·®
    train_error = np.mean(np.abs(train_pred - train_true))
    val_error = np.mean(np.abs(val_pred - val_true))
    
    print(f"\nğŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æœ:")
    print(f"è®­ç»ƒé›†å¹³å‡è¯¯å·®: {train_error:.6f}")
    print(f"éªŒè¯é›†å¹³å‡è¯¯å·®: {val_error:.6f}")
    print(f"æŸå¤±æ”¶æ•›æƒ…å†µ: åˆå§‹æŸå¤±={train_losses[0]:.6f}, æœ€ç»ˆæŸå¤±={train_losses[-1]:.6f}")
    
    if train_losses[-1] < train_losses[0] * 0.5:
        print("âœ… æŸå¤±æ˜æ˜¾æ”¶æ•›!")
    else:
        print("âš ï¸  æŸå¤±æ”¶æ•›ä¸å¤Ÿæ˜æ˜¾ï¼Œå¯èƒ½éœ€è¦æ›´å¤šè®­ç»ƒæˆ–è°ƒæ•´è¶…å‚æ•°")